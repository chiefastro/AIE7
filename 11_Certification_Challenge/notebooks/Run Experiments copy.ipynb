{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting population for all chunker types...\n",
            "Found 2 chunker types: ['naive_chunker', 'markdown_chunker']\n",
            "\n",
            "üîÑ Populating for chunker: naive_chunker\n",
            "==================================================\n",
            "Initializing config with: {'agent_type': 'supervisor', 'chunker_type': 'naive_chunker', 'retriever_type': 'cosine'}\n",
            "Config initialized successfully: {'agent_type': 'supervisor', 'chunker_type': 'naive_chunker', 'retriever_type': 'cosine'}\n",
            "Starting pipeline with docs path: data\n",
            "Searching for .md files in: /Users/jrand/git-repos/AIE7/11_Certification_Challenge/notebooks/data\n",
            "Found 0 .md files: []\n",
            "Total documents loaded: 0\n",
            "Documents loaded: 0\n",
            "Using chunker: naive_chunker\n",
            "Chunks created: 0\n",
            "‚ùå Failed to populate for naive_chunker: list index out of range\n",
            "Full traceback:\n",
            "Resetting config for naive_chunker\n",
            "‚ùå Failed to populate for naive_chunker: list index out of range\n",
            "Full traceback:\n",
            "\n",
            "üîÑ Populating for chunker: markdown_chunker\n",
            "==================================================\n",
            "Initializing config with: {'agent_type': 'supervisor', 'chunker_type': 'markdown_chunker', 'retriever_type': 'cosine'}\n",
            "Config initialized successfully: {'agent_type': 'supervisor', 'chunker_type': 'markdown_chunker', 'retriever_type': 'cosine'}\n",
            "Starting pipeline with docs path: data\n",
            "Searching for .md files in: /Users/jrand/git-repos/AIE7/11_Certification_Challenge/notebooks/data\n",
            "Found 0 .md files: []\n",
            "Total documents loaded: 0\n",
            "Documents loaded: 0\n",
            "Using chunker: markdown_chunker\n",
            "Chunks created: 0\n",
            "‚ùå Failed to populate for markdown_chunker: list index out of range\n",
            "Full traceback:\n",
            "Resetting config for markdown_chunker\n",
            "‚ùå Failed to populate for markdown_chunker: list index out of range\n",
            "Full traceback:\n",
            "\n",
            "üéâ Population completed for all chunker types!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/populate_all.py\", line 40, in populate_for_chunker\n",
            "    result = pipe(docs_path)\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/pipe.py\", line 28, in pipe\n",
            "    vectorstore = index(chunks)\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/index.py\", line 14, in index\n",
            "    qdrant_vectorstore = Qdrant.from_documents(\n",
            "        documents=chunks,\n",
            "    ...<3 lines>...\n",
            "        force_recreate=True  # Overwrite existing collection\n",
            "    )\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_core/vectorstores/base.py\", line 848, in from_documents\n",
            "    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n",
            "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_community/vectorstores/qdrant.py\", line 1337, in from_texts\n",
            "    qdrant = cls.construct_instance(\n",
            "        texts,\n",
            "    ...<28 lines>...\n",
            "        **kwargs,\n",
            "    )\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_community/vectorstores/qdrant.py\", line 1640, in construct_instance\n",
            "    vector_size = len(partial_embeddings[0])\n",
            "                      ~~~~~~~~~~~~~~~~~~^^^\n",
            "IndexError: list index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/populate_all.py\", line 66, in main\n",
            "    populate_for_chunker(chunker_type)\n",
            "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/populate_all.py\", line 40, in populate_for_chunker\n",
            "    result = pipe(docs_path)\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/pipe.py\", line 28, in pipe\n",
            "    vectorstore = index(chunks)\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/index.py\", line 14, in index\n",
            "    qdrant_vectorstore = Qdrant.from_documents(\n",
            "        documents=chunks,\n",
            "    ...<3 lines>...\n",
            "        force_recreate=True  # Overwrite existing collection\n",
            "    )\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_core/vectorstores/base.py\", line 848, in from_documents\n",
            "    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n",
            "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_community/vectorstores/qdrant.py\", line 1337, in from_texts\n",
            "    qdrant = cls.construct_instance(\n",
            "        texts,\n",
            "    ...<28 lines>...\n",
            "        **kwargs,\n",
            "    )\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_community/vectorstores/qdrant.py\", line 1640, in construct_instance\n",
            "    vector_size = len(partial_embeddings[0])\n",
            "                      ~~~~~~~~~~~~~~~~~~^^^\n",
            "IndexError: list index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/populate_all.py\", line 40, in populate_for_chunker\n",
            "    result = pipe(docs_path)\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/pipe.py\", line 28, in pipe\n",
            "    vectorstore = index(chunks)\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/index.py\", line 14, in index\n",
            "    qdrant_vectorstore = Qdrant.from_documents(\n",
            "        documents=chunks,\n",
            "    ...<3 lines>...\n",
            "        force_recreate=True  # Overwrite existing collection\n",
            "    )\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_core/vectorstores/base.py\", line 848, in from_documents\n",
            "    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n",
            "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_community/vectorstores/qdrant.py\", line 1337, in from_texts\n",
            "    qdrant = cls.construct_instance(\n",
            "        texts,\n",
            "    ...<28 lines>...\n",
            "        **kwargs,\n",
            "    )\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_community/vectorstores/qdrant.py\", line 1640, in construct_instance\n",
            "    vector_size = len(partial_embeddings[0])\n",
            "                      ~~~~~~~~~~~~~~~~~~^^^\n",
            "IndexError: list index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/populate_all.py\", line 66, in main\n",
            "    populate_for_chunker(chunker_type)\n",
            "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/populate_all.py\", line 40, in populate_for_chunker\n",
            "    result = pipe(docs_path)\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/pipe.py\", line 28, in pipe\n",
            "    vectorstore = index(chunks)\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/pipe/index.py\", line 14, in index\n",
            "    qdrant_vectorstore = Qdrant.from_documents(\n",
            "        documents=chunks,\n",
            "    ...<3 lines>...\n",
            "        force_recreate=True  # Overwrite existing collection\n",
            "    )\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_core/vectorstores/base.py\", line 848, in from_documents\n",
            "    return cls.from_texts(texts, embedding, metadatas=metadatas, **kwargs)\n",
            "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_community/vectorstores/qdrant.py\", line 1337, in from_texts\n",
            "    qdrant = cls.construct_instance(\n",
            "        texts,\n",
            "    ...<28 lines>...\n",
            "        **kwargs,\n",
            "    )\n",
            "  File \"/Users/jrand/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_community/vectorstores/qdrant.py\", line 1640, in construct_instance\n",
            "    vector_size = len(partial_embeddings[0])\n",
            "                      ~~~~~~~~~~~~~~~~~~^^^\n",
            "IndexError: list index out of range\n"
          ]
        }
      ],
      "source": [
        "from mimi.pipe.populate_all import main\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jrand/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/agents/__init__.py:1: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  from mimi.agents.supervisor import create_supervisor_graph\n"
          ]
        }
      ],
      "source": [
        "from mimi.evals.ragas_eval import generate_all_invocables\n",
        "from mimi.evals.ragas_csv_loader import load_ragas_csv\n",
        "from mimi.evals.ragas_eval import run_ragas_eval_parallel, run_ragas_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate all combinations\n",
        "invocables = generate_all_invocables()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = load_ragas_csv(f\"../data/sdg/testset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run all experiments - Qdrant won't let them run in parallel\n",
        "# results = run_ragas_eval_parallel(invocables, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Collection naive_chunker not found",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m results_d = {\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     invocable_name: \u001b[43mrun_ragas_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43minvocable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvocable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m invocable_name, invocable \n\u001b[32m      4\u001b[39m     \u001b[38;5;129;01min\u001b[39;00m invocables.items()\n\u001b[32m      5\u001b[39m }\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/evals/ragas_eval.py:33\u001b[39m, in \u001b[36mrun_ragas_eval\u001b[39m\u001b[34m(invocable, invocable_name, dataset)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m test_row \u001b[38;5;129;01min\u001b[39;00m dataset_this:\n\u001b[32m     25\u001b[39m   \u001b[38;5;66;03m# Provide proper config for the checkpointer\u001b[39;00m\n\u001b[32m     26\u001b[39m   config = {\n\u001b[32m     27\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     28\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexperiment_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minvocable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muuid.uuid4()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m       },\n\u001b[32m     30\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: [invocable_name]\n\u001b[32m     31\u001b[39m   }\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m   response = \u001b[43minvocable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_row\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval_sample\u001b[49m\u001b[43m.\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m   test_row.eval_sample.response = response[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     35\u001b[39m   test_row.eval_sample.retrieved_contexts = [context.page_content \u001b[38;5;28;01mfor\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m]]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/agents/rag.py:24\u001b[39m, in \u001b[36mretrieve\u001b[39m\u001b[34m(state, config, chunker_type, retriever_type, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve\u001b[39m(state: State, config: \u001b[38;5;28mdict\u001b[39m, chunker_type: \u001b[38;5;28mstr\u001b[39m = CHUNKER_TYPE, retriever_type: \u001b[38;5;28mstr\u001b[39m = RETRIEVER_TYPE, **kwargs) -> State:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m   retrieved_docs = \u001b[43mget_retriever\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunker_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunker_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretriever_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m.invoke(state[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m], config=config)\n\u001b[32m     27\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m : retrieved_docs}\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/AIE7/11_Certification_Challenge/backend/src/mimi/tools/retriever.py:26\u001b[39m, in \u001b[36mget_retriever\u001b[39m\u001b[34m(chunker_type, retriever_type, **kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Connect to existing vector store\u001b[39;00m\n\u001b[32m     25\u001b[39m client = QdrantClient(path=PERSIST_DIR)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m vectorstore = \u001b[43mQdrantVectorStore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunker_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Create retriever\u001b[39;00m\n\u001b[32m     33\u001b[39m retriever = vectorstore.as_retriever(**kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_qdrant/qdrant.py:213\u001b[39m, in \u001b[36mQdrantVectorStore.__init__\u001b[39m\u001b[34m(self, client, collection_name, embedding, retrieval_mode, vector_name, content_payload_key, metadata_payload_key, distance, sparse_embedding, sparse_vector_name, validate_embeddings, validate_collection_config)\u001b[39m\n\u001b[32m    210\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_embeddings(retrieval_mode, embedding, sparse_embedding)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate_collection_config:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_collection_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretrieval_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvector_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43msparse_vector_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[38;5;28mself\u001b[39m._client = client\n\u001b[32m    224\u001b[39m \u001b[38;5;28mself\u001b[39m.collection_name = collection_name\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_qdrant/qdrant.py:1050\u001b[39m, in \u001b[36mQdrantVectorStore._validate_collection_config\u001b[39m\u001b[34m(cls, client, collection_name, retrieval_mode, vector_name, sparse_vector_name, distance, embedding)\u001b[39m\n\u001b[32m   1038\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_collection_config\u001b[39m(\n\u001b[32m   1040\u001b[39m     \u001b[38;5;28mcls\u001b[39m: Type[QdrantVectorStore],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1047\u001b[39m     embedding: Optional[Embeddings],\n\u001b[32m   1048\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m retrieval_mode == RetrievalMode.DENSE:\n\u001b[32m-> \u001b[39m\u001b[32m1050\u001b[39m         \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_collection_for_dense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m retrieval_mode == RetrievalMode.SPARSE:\n\u001b[32m   1055\u001b[39m         \u001b[38;5;28mcls\u001b[39m._validate_collection_for_sparse(\n\u001b[32m   1056\u001b[39m             client, collection_name, sparse_vector_name\n\u001b[32m   1057\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/langchain_qdrant/qdrant.py:1076\u001b[39m, in \u001b[36mQdrantVectorStore._validate_collection_for_dense\u001b[39m\u001b[34m(cls, client, collection_name, vector_name, distance, dense_embeddings)\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1068\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_collection_for_dense\u001b[39m(\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28mcls\u001b[39m: Type[QdrantVectorStore],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1074\u001b[39m     dense_embeddings: Union[Embeddings, List[\u001b[38;5;28mfloat\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[32m   1075\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1076\u001b[39m     collection_info = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m     vector_config = collection_info.config.params.vectors\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(vector_config, Dict):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# vector_config is a Dict[str, VectorParams]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/qdrant_client/qdrant_client.py:2223\u001b[39m, in \u001b[36mQdrantClient.get_collection\u001b[39m\u001b[34m(self, collection_name, **kwargs)\u001b[39m\n\u001b[32m   2213\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get detailed information about specified existing collection\u001b[39;00m\n\u001b[32m   2214\u001b[39m \n\u001b[32m   2215\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2219\u001b[39m \u001b[33;03m    Detailed information about the collection\u001b[39;00m\n\u001b[32m   2220\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2221\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) == \u001b[32m0\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2223\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/qdrant_client/local/qdrant_local.py:940\u001b[39m, in \u001b[36mQdrantLocal.get_collection\u001b[39m\u001b[34m(self, collection_name, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_collection\u001b[39m(\u001b[38;5;28mself\u001b[39m, collection_name: \u001b[38;5;28mstr\u001b[39m, **kwargs: Any) -> types.CollectionInfo:\n\u001b[32m--> \u001b[39m\u001b[32m940\u001b[39m     collection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    941\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m collection.info()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/AIE7/11_Certification_Challenge/.venv/lib/python3.13/site-packages/qdrant_client/local/qdrant_local.py:172\u001b[39m, in \u001b[36mQdrantLocal._get_collection\u001b[39m\u001b[34m(self, collection_name)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collection_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aliases:\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.collections[\u001b[38;5;28mself\u001b[39m.aliases[collection_name]]\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mValueError\u001b[39m: Collection naive_chunker not found",
            "During task with name 'retrieve' and id '45b14fc1-e69d-a39f-e60c-4411f051dfa2'"
          ]
        }
      ],
      "source": [
        "results_d = {\n",
        "    invocable_name: run_ragas_eval(invocable, invocable_name, dataset)\n",
        "    for invocable_name, invocable \n",
        "    in invocables.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>factual_correctness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>experiment_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>naive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.522727</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.941829</td>\n",
              "      <td>naive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.987586</td>\n",
              "      <td>naive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.960614</td>\n",
              "      <td>naive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.944441</td>\n",
              "      <td>naive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>semantic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.951291</td>\n",
              "      <td>semantic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>semantic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.934657</td>\n",
              "      <td>semantic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.923703</td>\n",
              "      <td>semantic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70 rows √ó 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    context_recall  faithfulness  factual_correctness  answer_relevancy  \\\n",
              "0              1.0      0.555556                 0.18          0.000000   \n",
              "1              1.0      0.522727                 0.15          0.941829   \n",
              "2              1.0      0.666667                 0.50          0.987586   \n",
              "3              0.0      0.000000                 0.24          0.960614   \n",
              "4              1.0      0.941176                 0.71          0.944441   \n",
              "..             ...           ...                  ...               ...   \n",
              "5              1.0      0.878788                 0.62          0.000000   \n",
              "6              NaN      0.880952                 0.88          0.951291   \n",
              "7              1.0      0.750000                 0.37          0.000000   \n",
              "8              1.0      0.825000                  NaN          0.934657   \n",
              "9              1.0      0.944444                 0.78          0.923703   \n",
              "\n",
              "   experiment_name  \n",
              "0            naive  \n",
              "1            naive  \n",
              "2            naive  \n",
              "3            naive  \n",
              "4            naive  \n",
              "..             ...  \n",
              "5         semantic  \n",
              "6         semantic  \n",
              "7         semantic  \n",
              "8         semantic  \n",
              "9         semantic  \n",
              "\n",
              "[70 rows x 5 columns]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "score_dfs = []\n",
        "for name, result in results_d.items():\n",
        "    score_df = pd.DataFrame(result.scores)\n",
        "    score_df['experiment_name'] = name\n",
        "    score_dfs.append(score_df)\n",
        "\n",
        "score_df = pd.concat(score_dfs)\n",
        "score_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "score_df = pd.read_csv(\"../data/experiments/score_df_123e4567-e89b-12d3-a456-426614174000.csv\")\n",
        "\n",
        "score_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>factual_correctness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>experiment_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bm25</th>\n",
              "      <td>0.633333</td>\n",
              "      <td>0.640254</td>\n",
              "      <td>0.562222</td>\n",
              "      <td>0.749486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contextual_compression</th>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.768561</td>\n",
              "      <td>0.612857</td>\n",
              "      <td>0.842251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble</th>\n",
              "      <td>0.966667</td>\n",
              "      <td>0.858049</td>\n",
              "      <td>0.455000</td>\n",
              "      <td>0.665007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>multi_query</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900093</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>0.735416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>naive</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.731857</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.824444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parent_document</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.787431</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>0.742986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>semantic</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.777018</td>\n",
              "      <td>0.578571</td>\n",
              "      <td>0.663101</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        context_recall  faithfulness  factual_correctness  \\\n",
              "experiment_name                                                             \n",
              "bm25                          0.633333      0.640254             0.562222   \n",
              "contextual_compression        0.683333      0.768561             0.612857   \n",
              "ensemble                      0.966667      0.858049             0.455000   \n",
              "multi_query                   1.000000      0.900093             0.616667   \n",
              "naive                         0.833333      0.731857             0.507500   \n",
              "parent_document               0.833333      0.787431             0.475000   \n",
              "semantic                      1.000000      0.777018             0.578571   \n",
              "\n",
              "                        answer_relevancy  \n",
              "experiment_name                           \n",
              "bm25                            0.749486  \n",
              "contextual_compression          0.842251  \n",
              "ensemble                        0.665007  \n",
              "multi_query                     0.735416  \n",
              "naive                           0.824444  \n",
              "parent_document                 0.742986  \n",
              "semantic                        0.663101  "
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score_aggs = score_df.groupby('experiment_name').mean()\n",
        "score_aggs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['naive', 'bm25', 'contextual_compression', 'multi_query', 'parent_document', 'ensemble', 'semantic'])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "tags = list(invocables.keys())\n",
        "by_tag = defaultdict(dict)\n",
        "\n",
        "for t in tqdm(tags):\n",
        "    by_tag[t] = client.get_run_stats(\n",
        "        project_names=[os.environ[\"LANGSMITH_PROJECT\"]],\n",
        "        # filter syntax lets you match an element in the tags array\n",
        "        filter=f\"has(tags, '{t}')\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_count</th>\n",
              "      <th>latency_p50</th>\n",
              "      <th>latency_p99</th>\n",
              "      <th>first_token_p50</th>\n",
              "      <th>first_token_p99</th>\n",
              "      <th>total_tokens</th>\n",
              "      <th>prompt_tokens</th>\n",
              "      <th>completion_tokens</th>\n",
              "      <th>median_tokens</th>\n",
              "      <th>completion_tokens_p50</th>\n",
              "      <th>...</th>\n",
              "      <th>last_run_start_time</th>\n",
              "      <th>feedback_stats</th>\n",
              "      <th>run_facets</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>streaming_rate</th>\n",
              "      <th>total_cost</th>\n",
              "      <th>prompt_cost</th>\n",
              "      <th>completion_cost</th>\n",
              "      <th>cost_p50</th>\n",
              "      <th>cost_p99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>naive</th>\n",
              "      <td>140</td>\n",
              "      <td>0.097</td>\n",
              "      <td>5.97622</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>78448</td>\n",
              "      <td>75422</td>\n",
              "      <td>3026</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2025-07-29T18:07:50.680775</td>\n",
              "      <td>{}</td>\n",
              "      <td>[{'key': 'name', 'value': 'RunnableLambda', 'q...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008753</td>\n",
              "      <td>0.007542</td>\n",
              "      <td>0.00121</td>\n",
              "      <td>0.000856</td>\n",
              "      <td>0.00128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bm25</th>\n",
              "      <td>140</td>\n",
              "      <td>0.004</td>\n",
              "      <td>5.53122</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>44496</td>\n",
              "      <td>41779</td>\n",
              "      <td>2717</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2025-07-29T18:07:44.704082</td>\n",
              "      <td>{}</td>\n",
              "      <td>[{'key': 'name', 'value': 'RunnableLambda', 'q...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005265</td>\n",
              "      <td>0.004178</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>0.000536</td>\n",
              "      <td>0.000795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contextual_compression</th>\n",
              "      <td>150</td>\n",
              "      <td>0.2925</td>\n",
              "      <td>8.65653</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>29567</td>\n",
              "      <td>27045</td>\n",
              "      <td>2522</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2025-07-29T18:07:49.042365</td>\n",
              "      <td>{}</td>\n",
              "      <td>[{'key': 'name', 'value': 'RunnableLambda', 'q...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003713</td>\n",
              "      <td>0.002704</td>\n",
              "      <td>0.001009</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.000643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>multi_query</th>\n",
              "      <td>210</td>\n",
              "      <td>0.267</td>\n",
              "      <td>10.06614</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>109729</td>\n",
              "      <td>105427</td>\n",
              "      <td>4302</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2025-07-29T18:08:26.420350</td>\n",
              "      <td>{}</td>\n",
              "      <td>[{'key': 'name', 'value': 'RunnableLambda', 'q...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01163</td>\n",
              "      <td>0.009909</td>\n",
              "      <td>0.001721</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.001536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parent_document</th>\n",
              "      <td>140</td>\n",
              "      <td>0.111</td>\n",
              "      <td>11.36261</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>43181</td>\n",
              "      <td>40126</td>\n",
              "      <td>3055</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2025-07-29T18:08:05.123571</td>\n",
              "      <td>{}</td>\n",
              "      <td>[{'key': 'name', 'value': 'RunnableLambda', 'q...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005235</td>\n",
              "      <td>0.004013</td>\n",
              "      <td>0.001222</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>0.000912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble</th>\n",
              "      <td>270</td>\n",
              "      <td>0.311</td>\n",
              "      <td>24.77662</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>161680</td>\n",
              "      <td>157113</td>\n",
              "      <td>4567</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2025-07-29T18:08:55.882714</td>\n",
              "      <td>{}</td>\n",
              "      <td>[{'key': 'name', 'value': 'VectorStoreRetrieve...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017538</td>\n",
              "      <td>0.015711</td>\n",
              "      <td>0.001827</td>\n",
              "      <td>0.000487</td>\n",
              "      <td>0.002717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>semantic</th>\n",
              "      <td>140</td>\n",
              "      <td>0.089</td>\n",
              "      <td>9.86083</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>67636</td>\n",
              "      <td>64023</td>\n",
              "      <td>3613</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2025-07-29T18:07:50.507913</td>\n",
              "      <td>{}</td>\n",
              "      <td>[{'key': 'name', 'value': 'RunnableLambda', 'q...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007848</td>\n",
              "      <td>0.006402</td>\n",
              "      <td>0.001445</td>\n",
              "      <td>0.000821</td>\n",
              "      <td>0.000982</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7 rows √ó 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       run_count latency_p50 latency_p99 first_token_p50  \\\n",
              "naive                        140       0.097     5.97622            None   \n",
              "bm25                         140       0.004     5.53122            None   \n",
              "contextual_compression       150      0.2925     8.65653            None   \n",
              "multi_query                  210       0.267    10.06614            None   \n",
              "parent_document              140       0.111    11.36261            None   \n",
              "ensemble                     270       0.311    24.77662            None   \n",
              "semantic                     140       0.089     9.86083            None   \n",
              "\n",
              "                       first_token_p99 total_tokens prompt_tokens  \\\n",
              "naive                             None        78448         75422   \n",
              "bm25                              None        44496         41779   \n",
              "contextual_compression            None        29567         27045   \n",
              "multi_query                       None       109729        105427   \n",
              "parent_document                   None        43181         40126   \n",
              "ensemble                          None       161680        157113   \n",
              "semantic                          None        67636         64023   \n",
              "\n",
              "                       completion_tokens median_tokens completion_tokens_p50  \\\n",
              "naive                               3026             0                     0   \n",
              "bm25                                2717             0                     0   \n",
              "contextual_compression              2522             0                     0   \n",
              "multi_query                         4302             0                     0   \n",
              "parent_document                     3055             0                     0   \n",
              "ensemble                            4567             0                     0   \n",
              "semantic                            3613             0                     0   \n",
              "\n",
              "                        ...         last_run_start_time feedback_stats  \\\n",
              "naive                   ...  2025-07-29T18:07:50.680775             {}   \n",
              "bm25                    ...  2025-07-29T18:07:44.704082             {}   \n",
              "contextual_compression  ...  2025-07-29T18:07:49.042365             {}   \n",
              "multi_query             ...  2025-07-29T18:08:26.420350             {}   \n",
              "parent_document         ...  2025-07-29T18:08:05.123571             {}   \n",
              "ensemble                ...  2025-07-29T18:08:55.882714             {}   \n",
              "semantic                ...  2025-07-29T18:07:50.507913             {}   \n",
              "\n",
              "                                                               run_facets  \\\n",
              "naive                   [{'key': 'name', 'value': 'RunnableLambda', 'q...   \n",
              "bm25                    [{'key': 'name', 'value': 'RunnableLambda', 'q...   \n",
              "contextual_compression  [{'key': 'name', 'value': 'RunnableLambda', 'q...   \n",
              "multi_query             [{'key': 'name', 'value': 'RunnableLambda', 'q...   \n",
              "parent_document         [{'key': 'name', 'value': 'RunnableLambda', 'q...   \n",
              "ensemble                [{'key': 'name', 'value': 'VectorStoreRetrieve...   \n",
              "semantic                [{'key': 'name', 'value': 'RunnableLambda', 'q...   \n",
              "\n",
              "                       error_rate streaming_rate total_cost prompt_cost  \\\n",
              "naive                         0.0            0.0   0.008753    0.007542   \n",
              "bm25                          0.0            0.0   0.005265    0.004178   \n",
              "contextual_compression        0.0            0.0   0.003713    0.002704   \n",
              "multi_query                   0.0            0.0    0.01163    0.009909   \n",
              "parent_document               0.0            0.0   0.005235    0.004013   \n",
              "ensemble                      0.0            0.0   0.017538    0.015711   \n",
              "semantic                      0.0            0.0   0.007848    0.006402   \n",
              "\n",
              "                       completion_cost  cost_p50  cost_p99  \n",
              "naive                          0.00121  0.000856   0.00128  \n",
              "bm25                          0.001087  0.000536  0.000795  \n",
              "contextual_compression        0.001009  0.000342  0.000643  \n",
              "multi_query                   0.001721  0.000288  0.001536  \n",
              "parent_document               0.001222  0.000406  0.000912  \n",
              "ensemble                      0.001827  0.000487  0.002717  \n",
              "semantic                      0.001445  0.000821  0.000982  \n",
              "\n",
              "[7 rows x 24 columns]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "langsmith_df = pd.DataFrame(by_tag).T\n",
        "langsmith_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>factual_correctness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>latency_p50</th>\n",
              "      <th>latency_p99</th>\n",
              "      <th>cost_p50</th>\n",
              "      <th>cost_p99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bm25</th>\n",
              "      <td>0.633333</td>\n",
              "      <td>0.640254</td>\n",
              "      <td>0.562222</td>\n",
              "      <td>0.749486</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>-5.53122</td>\n",
              "      <td>-0.000536</td>\n",
              "      <td>-0.000795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contextual_compression</th>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.768561</td>\n",
              "      <td>0.612857</td>\n",
              "      <td>0.842251</td>\n",
              "      <td>-0.2925</td>\n",
              "      <td>-8.65653</td>\n",
              "      <td>-0.000342</td>\n",
              "      <td>-0.000643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble</th>\n",
              "      <td>0.966667</td>\n",
              "      <td>0.858049</td>\n",
              "      <td>0.455000</td>\n",
              "      <td>0.665007</td>\n",
              "      <td>-0.311</td>\n",
              "      <td>-24.77662</td>\n",
              "      <td>-0.000487</td>\n",
              "      <td>-0.002717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>multi_query</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900093</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>0.735416</td>\n",
              "      <td>-0.267</td>\n",
              "      <td>-10.06614</td>\n",
              "      <td>-0.000288</td>\n",
              "      <td>-0.001536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>naive</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.731857</td>\n",
              "      <td>0.507500</td>\n",
              "      <td>0.824444</td>\n",
              "      <td>-0.097</td>\n",
              "      <td>-5.97622</td>\n",
              "      <td>-0.000856</td>\n",
              "      <td>-0.00128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parent_document</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.787431</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>0.742986</td>\n",
              "      <td>-0.111</td>\n",
              "      <td>-11.36261</td>\n",
              "      <td>-0.000406</td>\n",
              "      <td>-0.000912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>semantic</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.777018</td>\n",
              "      <td>0.578571</td>\n",
              "      <td>0.663101</td>\n",
              "      <td>-0.089</td>\n",
              "      <td>-9.86083</td>\n",
              "      <td>-0.000821</td>\n",
              "      <td>-0.000982</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        context_recall  faithfulness  factual_correctness  \\\n",
              "bm25                          0.633333      0.640254             0.562222   \n",
              "contextual_compression        0.683333      0.768561             0.612857   \n",
              "ensemble                      0.966667      0.858049             0.455000   \n",
              "multi_query                   1.000000      0.900093             0.616667   \n",
              "naive                         0.833333      0.731857             0.507500   \n",
              "parent_document               0.833333      0.787431             0.475000   \n",
              "semantic                      1.000000      0.777018             0.578571   \n",
              "\n",
              "                        answer_relevancy latency_p50 latency_p99  cost_p50  \\\n",
              "bm25                            0.749486      -0.004    -5.53122 -0.000536   \n",
              "contextual_compression          0.842251     -0.2925    -8.65653 -0.000342   \n",
              "ensemble                        0.665007      -0.311   -24.77662 -0.000487   \n",
              "multi_query                     0.735416      -0.267   -10.06614 -0.000288   \n",
              "naive                           0.824444      -0.097    -5.97622 -0.000856   \n",
              "parent_document                 0.742986      -0.111   -11.36261 -0.000406   \n",
              "semantic                        0.663101      -0.089    -9.86083 -0.000821   \n",
              "\n",
              "                        cost_p99  \n",
              "bm25                   -0.000795  \n",
              "contextual_compression -0.000643  \n",
              "ensemble               -0.002717  \n",
              "multi_query            -0.001536  \n",
              "naive                   -0.00128  \n",
              "parent_document        -0.000912  \n",
              "semantic               -0.000982  "
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score_aggs_combined = pd.concat([score_aggs, -langsmith_df[['latency_p50', 'latency_p99', 'cost_p50', 'cost_p99']]], axis=1)\n",
        "score_aggs_combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>factual_correctness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>latency_p50</th>\n",
              "      <th>latency_p99</th>\n",
              "      <th>cost_p50</th>\n",
              "      <th>cost_p99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bm25</th>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contextual_compression</th>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>multi_query</th>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>naive</th>\n",
              "      <td>4.5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parent_document</th>\n",
              "      <td>4.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>semantic</th>\n",
              "      <td>1.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        context_recall  faithfulness  factual_correctness  \\\n",
              "bm25                               7.0           7.0                  4.0   \n",
              "contextual_compression             6.0           5.0                  2.0   \n",
              "ensemble                           3.0           2.0                  7.0   \n",
              "multi_query                        1.5           1.0                  1.0   \n",
              "naive                              4.5           6.0                  5.0   \n",
              "parent_document                    4.5           3.0                  6.0   \n",
              "semantic                           1.5           4.0                  3.0   \n",
              "\n",
              "                        answer_relevancy  latency_p50  latency_p99  cost_p50  \\\n",
              "bm25                                 3.0          1.0          1.0       5.0   \n",
              "contextual_compression               1.0          6.0          3.0       2.0   \n",
              "ensemble                             6.0          7.0          7.0       4.0   \n",
              "multi_query                          5.0          5.0          5.0       1.0   \n",
              "naive                                2.0          3.0          2.0       7.0   \n",
              "parent_document                      4.0          4.0          6.0       3.0   \n",
              "semantic                             7.0          2.0          4.0       6.0   \n",
              "\n",
              "                        cost_p99  \n",
              "bm25                         2.0  \n",
              "contextual_compression       1.0  \n",
              "ensemble                     7.0  \n",
              "multi_query                  6.0  \n",
              "naive                        5.0  \n",
              "parent_document              3.0  \n",
              "semantic                     4.0  "
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score_aggs_combined.rank(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "experiment_name\n",
              "multi_query               2.125\n",
              "contextual_compression    3.500\n",
              "semantic                  3.875\n",
              "naive                     4.375\n",
              "parent_document           4.375\n",
              "ensemble                  4.500\n",
              "bm25                      5.250\n",
              "dtype: float64"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# aggregated rankings for evals only\n",
        "score_aggs.rank(ascending=False).mean(axis=1).sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "bm25                      2.25\n",
              "contextual_compression    3.00\n",
              "parent_document           4.00\n",
              "semantic                  4.00\n",
              "naive                     4.25\n",
              "multi_query               4.25\n",
              "ensemble                  6.25\n",
              "dtype: float64"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# aggregated rankings for cost/latency only\n",
        "(-langsmith_df[['latency_p50', 'latency_p99', 'cost_p50', 'cost_p99']]).rank(ascending=False).mean(axis=1).sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "multi_query               3.1875\n",
              "contextual_compression    3.2500\n",
              "bm25                      3.7500\n",
              "semantic                  3.9375\n",
              "parent_document           4.1875\n",
              "naive                     4.3125\n",
              "ensemble                  5.3750\n",
              "dtype: float64"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# aggregated rankings for both evals and cost/latency\n",
        "score_aggs_combined.rank(ascending=False).mean(axis=1).sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n",
        "\n",
        "The winner of my experiments is `multi_query`, which provides the optimal balance of quality, latency, and cost. The cell below provides a complete picture of how each retriever ranks compared to all other retrievers on 8 different dimensions.\n",
        "\n",
        "The rankings largely meet expectations. For example, bm25 is fast but has the worst accuracy. The ensemble is slow and expensive, but did not produce enough accuracy boost to justify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context_recall</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>factual_correctness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>latency_p50</th>\n",
              "      <th>latency_p99</th>\n",
              "      <th>cost_p50</th>\n",
              "      <th>cost_p99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bm25</th>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contextual_compression</th>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>multi_query</th>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>naive</th>\n",
              "      <td>4.5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parent_document</th>\n",
              "      <td>4.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>semantic</th>\n",
              "      <td>1.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        context_recall  faithfulness  factual_correctness  \\\n",
              "bm25                               7.0           7.0                  4.0   \n",
              "contextual_compression             6.0           5.0                  2.0   \n",
              "ensemble                           3.0           2.0                  7.0   \n",
              "multi_query                        1.5           1.0                  1.0   \n",
              "naive                              4.5           6.0                  5.0   \n",
              "parent_document                    4.5           3.0                  6.0   \n",
              "semantic                           1.5           4.0                  3.0   \n",
              "\n",
              "                        answer_relevancy  latency_p50  latency_p99  cost_p50  \\\n",
              "bm25                                 3.0          1.0          1.0       5.0   \n",
              "contextual_compression               1.0          6.0          3.0       2.0   \n",
              "ensemble                             6.0          7.0          7.0       4.0   \n",
              "multi_query                          5.0          5.0          5.0       1.0   \n",
              "naive                                2.0          3.0          2.0       7.0   \n",
              "parent_document                      4.0          4.0          6.0       3.0   \n",
              "semantic                             7.0          2.0          4.0       6.0   \n",
              "\n",
              "                        cost_p99  \n",
              "bm25                         2.0  \n",
              "contextual_compression       1.0  \n",
              "ensemble                     7.0  \n",
              "multi_query                  6.0  \n",
              "naive                        5.0  \n",
              "parent_document              3.0  \n",
              "semantic                     4.0  "
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score_aggs_combined.rank(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
